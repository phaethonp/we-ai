{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phaethonp/we-ai/blob/main/IFC2JSON.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ifcopenshell\n",
        "!pip install pandas-profiling\n"
      ],
      "metadata": {
        "id": "dfUcr8mLRmG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gMUgq-Apbwpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IFC TO JSON ##\n"
      ],
      "metadata": {
        "id": "uT97ymdGUFqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import ifcopenshell\n",
        "import os\n",
        "import uuid\n",
        "import ifcopenshell\n",
        "import ifcopenshell.geom\n",
        "import ifcopenshell.guid as guid\n",
        "from datetime import datetime\n",
        "from ifcopenshell.entity_instance import entity_instance\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "4l_ULQWUmiB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EL9m9eXFg5aJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IFC2JSON:\n",
        "    \"\"\"Base class for all IFC SPF to IFC.JSON writers\n",
        "    \"\"\"\n",
        "\n",
        "    VERSION = '0.0.1'\n",
        "\n",
        "    DIMENSIONALEXPONENTS = {\n",
        "        'METRE': (1, 0, 0, 0, 0, 0, 0),\n",
        "        'SQUARE_METRE': (2, 0, 0, 0, 0, 0, 0),\n",
        "        'CUBIC_METRE': (3, 0, 0, 0, 0, 0, 0),\n",
        "        'GRAM': (0, 1, 0, 0, 0, 0, 0),\n",
        "        'SECOND': (0, 0, 1, 0, 0, 0, 0),\n",
        "        'AMPERE': (0, 0, 0, 1, 0, 0, 0),\n",
        "        'KELVIN': (0, 0, 0, 0, 1, 0, 0),\n",
        "        'MOLE': (0, 0, 0, 0, 0, 1, 0),\n",
        "        'CANDELA': (0, 0, 0, 0, 0, 0, 1),\n",
        "        'RADIAN': (0, 0, 0, 0, 0, 0, 0),\n",
        "        'STERADIAN': (0, 0, 0, 0, 0, 0, 0),\n",
        "        'HERTZ': (0, 0, -1, 0, 0, 0, 0),\n",
        "        'NEWTON': (1, 1, -2, 0, 0, 0, 0),\n",
        "        'PASCAL': (-1, 1, -2, 0, 0, 0, 0),\n",
        "        'JOULE': (2, 1, -2, 0, 0, 0, 0),\n",
        "        'WATT': (2, 1, -3, 0, 0, 0, 0),\n",
        "        'COULOMB': (0, 0, 1, 1, 0, 0, 0),\n",
        "        'VOLT': (2, 1, -3, -1, 0, 0, 0),\n",
        "        'FARAD': (-2, -1, 4, 2, 0, 0, 0),\n",
        "        'OHM': (2, 1, -3, -2, 0, 0, 0),\n",
        "        'SIEMENS': (-2, -1, 3, 2, 0, 0, 0),\n",
        "        'WEBER': (2, 1, -2, -1, 0, 0, 0),\n",
        "        'TESLA': (0, 1, -2, -1, 0, 0, 0),\n",
        "        'HENRY': (2, 1, -2, -2, 0, 0, 0),\n",
        "        'DEGREE_CELSIUS': (0, 0, 0, 0, 1, 0, 0),\n",
        "        'LUMEN': (0, 0, 0, 0, 0, 0, 1),\n",
        "        'LUX': (-2, 0, 0, 0, 0, 0, 1),\n",
        "        'BECQUEREL': (0, 0, -1, 0, 0, 0, 0),\n",
        "        'GRAY': (2, 0, -2, 0, 0, 0, 0),\n",
        "        'SIEVERT': (2, 0, -2, 0, 0, 0, 0),\n",
        "        'OTHERWISE': (0, 0, 0, 0, 0, 0, 0)\n",
        "    }\n",
        "\n",
        "    def toLowerCamelcase(self, string):\n",
        "        \"\"\"Convert string from upper to lower camelCase\"\"\"\n",
        "\n",
        "        return string[0].lower() + string[1:]\n",
        "\n",
        "    def getDimensionsForSiUnit(self, entity):\n",
        "        dimensions = {\n",
        "            'type': 'IfcDimensionalExponents'\n",
        "        }\n",
        "        if entity.Name in self.DIMENSIONALEXPONENTS:\n",
        "            dimExps = self.DIMENSIONALEXPONENTS[entity.Name]\n",
        "            if dimExps[0] != 0:\n",
        "                dimensions['LengthExponent'] = dimExps[0]\n",
        "            if dimExps[1] != 0:\n",
        "                dimensions['MassExponent'] = dimExps[1]\n",
        "            if dimExps[2] != 0:\n",
        "                dimensions['TimeExponent'] = dimExps[2]\n",
        "            if dimExps[3] != 0:\n",
        "                dimensions['ElectricCurrentExponent'] = dimExps[3]\n",
        "            if dimExps[4] != 0:\n",
        "                dimensions['ThermodynamicTemperatureExponent'] = dimExps[4]\n",
        "            if dimExps[5] != 0:\n",
        "                dimensions['AmountOfSubstanceExponent'] = dimExps[5]\n",
        "            if dimExps[6] != 0:\n",
        "                dimensions['LuminousIntensityExponent'] = dimExps[6]\n",
        "\n",
        "        return dimensions\n",
        "\n",
        "    def getAttributeValue(self, value):\n",
        "        \"\"\"Recursive method that walks through all nested objects of an attribute\n",
        "        and returns a IFC.JSON-4 model structure\n",
        "\n",
        "        Parameters:\n",
        "        value\n",
        "\n",
        "        Returns:\n",
        "        attribute data converted to IFC.JSON-4 model structure\n",
        "\n",
        "        \"\"\"\n",
        "        if value == None or value == '':\n",
        "            jsonValue = None\n",
        "        elif isinstance(value, ifcopenshell.entity_instance):\n",
        "            entity = value\n",
        "            entityAttributes = entity.__dict__\n",
        "\n",
        "            # Remove empty properties\n",
        "            if entity.is_a('IfcProperty'):\n",
        "                if not self.EMPTY_PROPERTIES:\n",
        "                    if self.empty_property(entity):\n",
        "                        return None\n",
        "\n",
        "            # Add unit dimensions https://standards.buildingsmart.org/IFC/DEV/IFC4_2/FINAL/HTML/schema/ifcmeasureresource/lexical/ifcdimensionsforsiunit.htm\n",
        "            if entity.is_a('IfcSIUnit'):\n",
        "                entityAttributes['dimensions'] = self.getDimensionsForSiUnit(\n",
        "                    entity)\n",
        "\n",
        "            # All objects with a GlobalId must be referenced, all others nested\n",
        "            if entity.id() in self.rootObjects:\n",
        "                entityAttributes[\"GlobalId\"] = self.rootObjects[entity.id()]\n",
        "                return self.createReferenceObject(entityAttributes, self.COMPACT)\n",
        "            else:\n",
        "                if 'GlobalId' in entityAttributes:\n",
        "                    entityAttributes[\"GlobalId\"] = guid.split(\n",
        "                        guid.expand(entity.GlobalId))[1:-1]\n",
        "\n",
        "            return self.createFullObject(entityAttributes)\n",
        "        elif isinstance(value, tuple):\n",
        "            jsonValue = tuple(x for x in map(\n",
        "                self.getAttributeValue, value) if x is not None)\n",
        "        else:\n",
        "            jsonValue = value\n",
        "        return jsonValue\n",
        "\n",
        "    def empty_property(self, entity):\n",
        "\n",
        "        # IfcPropertySingleValue\n",
        "        if hasattr(entity, 'NominalValue'):\n",
        "            if not entity.NominalValue:\n",
        "                return True\n",
        "            elif entity.NominalValue:\n",
        "                value = entity.NominalValue.wrappedValue\n",
        "                if (not value and value is not False) or (value == ''):\n",
        "                    return True\n",
        "\n",
        "        # IfcPropertyEnumeratedValue\n",
        "        elif hasattr(entity, 'EnumerationValues'):\n",
        "            if not entity.EnumerationValues:\n",
        "                return True\n",
        "\n",
        "        # IfcPropertyBoundedValue\n",
        "        elif hasattr(entity, 'UpperBoundValue'):\n",
        "            if not entity.UpperBoundValue and not entity.LowerBoundValue:\n",
        "                return True\n",
        "\n",
        "        # IfcPropertyTableValue\n",
        "        elif hasattr(entity, 'DefiningValues'):\n",
        "            if not entity.DefiningValues and not entity.DefinedValues:\n",
        "                return True\n"
      ],
      "metadata": {
        "id": "Pp-DyKpeUPgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The IFC2JSON5a class is a subclass of IFC2JSON that provides additional functionality for converting IfcProducts to OBJ meshes in the IFC.JSON-5a format.\n",
        "# It introduces the toObj method, which takes an ifcopenshell.ifcProduct instance and converts it to an OBJ string representing the geometry of the product. It uses the ifcopenshell.geom.create_shape function to create a shape representation of the product and then extracts the vertices and faces from the shape to generate the OBJ string.\n",
        "# The toObj method is called for each product with a representation, and the resulting OBJ string is added to the representations dictionary, which will be included in the final JSON output.\n",
        "# The spf2Json method is extended to handle the conversion of representations to OBJ and include them in the JSON output.\n",
        "# The createFullObject method is modified to exclude attributes that are not part of the IFC.JSON-5a format, as specified in the INVALIDATTRIBUTES attribute of the class.\n",
        "# The createFullObject method is also modified to flatten the object hierarchy by removing intermediate relationship objects specified in the SIMPLIFICATIONS attribute of the class.\n",
        "# Overall, the IFC2JSON5a class provides the capability to convert IfcProducts to OBJ meshes and include them in the IFC.JSON-5a output.\n",
        "\n",
        "class IFC2JSON5a(IFC2JSON):\n",
        "    SCHEMA_VERSION = '0.0.1'\n",
        "\n",
        "    # Attributes that are not part of IFC.JSON5a\n",
        "    INVALIDATTRIBUTES = {\n",
        "        'OwnerHistory',\n",
        "        'RepresentationContexts',\n",
        "        'ContextOfItems',\n",
        "        'ObjectPlacement',\n",
        "        'RepresentationMaps'\n",
        "    }\n",
        "\n",
        "    # Attributes for which the intermediate relationship object is removed\n",
        "    SIMPLIFICATIONS = {\n",
        "        # IfcRelAggregates\n",
        "        'IsDecomposedBy':       ['relatedObjects'],\n",
        "        'Decomposes':           ['relatingObject'],\n",
        "        # IfcRelContainedInSpatialStructure\n",
        "        'ContainsElements':     ['relatedElements'],\n",
        "        'ContainedInStructure': ['relatingStructure'],\n",
        "        # IfcRelDefinesByProperties\n",
        "        'IsDefinedBy':          ['relatingPropertyDefinition', 'relatingType'],\n",
        "        # IfcRelAssociatesMaterial\n",
        "        'HasAssociations':      ['relatingMaterial'],\n",
        "        # IfcRelFillsElement\n",
        "        'HasFillings':          ['relatedBuildingElement'],\n",
        "        'FillsVoids':           ['relatingOpeningElement'],\n",
        "        # IfcRelVoidsElement\n",
        "        'HasOpenings':          ['relatedOpeningElement'],\n",
        "        'VoidsElements':        ['relatingBuildingElement'],\n",
        "        # IfcRelDefinesByType\n",
        "        'ObjectTypeOf':         ['relatedObjects'],\n",
        "        'IsTypedBy':            ['relatingType'],\n",
        "        # IfcRelConnectsPathElements (!) This skips all IfcRelConnectsPathElements properties\n",
        "        'ConnectedTo':          ['relatedElement'],\n",
        "        'ConnectedFrom':        ['relatingElement'],\n",
        "        # IfcRelSpaceBoundary (!) This skips all spaceboundary properties like for example geometry\n",
        "        'BoundedBy':            ['relatedBuildingElement'],\n",
        "        'ProvidesBoundaries':   ['relatingSpace']\n",
        "    }\n",
        "\n",
        "    settings = ifcopenshell.geom.settings()\n",
        "    settings.USE_PYTHON_OPENCASCADE = True\n",
        "    settings.set(settings.USE_WORLD_COORDS, True)\n",
        "    settings.set(settings.EXCLUDE_SOLIDS_AND_SURFACES, False)\n",
        "\n",
        "    def __init__(self, ifcModel,\n",
        "                 COMPACT=False,\n",
        "                 EMPTY_PROPERTIES=False):\n",
        "        \"\"\"IFC SPF to IFC.JSON-5a writer\n",
        "\n",
        "        parameters:\n",
        "        ifcModel: IFC filePath or ifcopenshell model instance\n",
        "        COMPACT (boolean): if True then pretty print is turned off and references are created without informative \"type\" property\n",
        "\n",
        "        \"\"\"\n",
        "        if isinstance(ifcModel, ifcopenshell.file):\n",
        "            self.ifcModel = ifcModel\n",
        "        else:\n",
        "            self.ifcModel = ifcopenshell.open(ifcModel)\n",
        "        self.COMPACT = COMPACT\n",
        "        self.EMPTY_PROPERTIES = EMPTY_PROPERTIES\n",
        "\n",
        "        # Dictionary referencing all objects with a GlobalId that are already created\n",
        "        self.rootObjects = {}\n",
        "\n",
        "        # Representations are kept seperate to be added to the end of the list\n",
        "        self.representations = {}\n",
        "\n",
        "    def spf2Json(self):\n",
        "        \"\"\"\n",
        "        Create json dictionary structure for all attributes of the objects in the root list\n",
        "        (?) also including inverse attributes\n",
        "        (?) Check every IFC object to see if it is used multiple times\n",
        "\n",
        "        Returns:\n",
        "        dict: IFC.JSON-5a model structure\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        jsonObjects = []\n",
        "\n",
        "        for entity in self.ifcModel.by_type('IfcObjectDefinition'):\n",
        "            self.rootObjects[entity.id()] = guid.split(\n",
        "                guid.expand(entity.GlobalId))[1:-1]\n",
        "\n",
        "        for key in self.rootObjects:\n",
        "            entity = self.ifcModel.by_id(key)\n",
        "            entityAttributes = entity.__dict__\n",
        "            entityType = entityAttributes['type']\n",
        "            if not entityType in ['IfcGeometricRepresentationContext', 'IfcOwnerHistory']:\n",
        "                for attr in entity.wrapped_data.get_inverse_attribute_names():\n",
        "                    inverseAttribute = getattr(entity, attr)\n",
        "                    entityAttributes[attr] = self.getAttributeValue(\n",
        "                        inverseAttribute)\n",
        "            entityAttributes[\"GlobalId\"] = self.rootObjects[entity.id()]\n",
        "\n",
        "            # Convert representations to OBJ\n",
        "            if 'Representation' in entityAttributes:\n",
        "                obj = self.toObj(entity)\n",
        "\n",
        "                if obj:\n",
        "                    id = guid.split(guid.expand(guid.new()))[1:-1]\n",
        "                    ref = {}\n",
        "                    if not self.COMPACT:\n",
        "                        ref['type'] = \"shapeRepresentation\"\n",
        "                    ref['ref'] = id\n",
        "                    entityAttributes['representations'] = [ref]\n",
        "                    self.representations[id] = {\n",
        "                        \"type\": \"shapeRepresentation\",\n",
        "                        \"globalId\": id,\n",
        "                        \"representationIdentifier\": \"Body\",\n",
        "                        \"representationType\": \"OBJ\",\n",
        "                        \"items\": [\n",
        "                            obj\n",
        "                        ]\n",
        "                    }\n",
        "\n",
        "                # (!) delete original representation, even if OBJ generation fails\n",
        "                del entityAttributes['Representation']\n",
        "\n",
        "            jsonObjects.append(self.createFullObject(entityAttributes))\n",
        "\n",
        "        jsonObjects = jsonObjects + list(self.representations.values())\n",
        "\n",
        "        return {\n",
        "            'type': 'IFC.JSON-5a',\n",
        "            'version': self.SCHEMA_VERSION,\n",
        "            'schemaIdentifier': self.ifcModel.wrapped_data.schema,\n",
        "            'originatingSystem': 'IFC2JSON_python Version ' + self.VERSION,\n",
        "            'preprocessorVersion': 'IfcOpenShell ' + ifcopenshell.version,\n",
        "            'timeStamp': datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
        "            'data': jsonObjects\n",
        "        }\n",
        "\n",
        "    def createFullObject(self, entityAttributes):\n",
        "        \"\"\"Returns complete IFC.JSON-5a object\n",
        "\n",
        "        Parameters:\n",
        "        entityAttributes (dict): Dictionary of IFC object data\n",
        "\n",
        "        Returns:\n",
        "        dict: containing complete IFC.JSON-5a object\n",
        "\n",
        "        \"\"\"\n",
        "        fullObject = {}\n",
        "\n",
        "        for attr in entityAttributes:\n",
        "\n",
        "            # Line numbers are not part of IFC JSON\n",
        "            if attr == 'id':\n",
        "                continue\n",
        "\n",
        "            # Skip all IFC entities that are not part of IFC.JSON5a\n",
        "            if attr in self.INVALIDATTRIBUTES:\n",
        "                continue\n",
        "\n",
        "            # Flatten object hierarchy through removing intermediate relationship objects\n",
        "            if attr in self.SIMPLIFICATIONS:\n",
        "                for relObject in entityAttributes[attr]:\n",
        "                    for attrName in self.SIMPLIFICATIONS[attr]:\n",
        "\n",
        "                        # In case of propertysets, further simplification through removing intermediate PropertySets\n",
        "                        if attr == 'IsDefinedBy':\n",
        "                            if relObject['type'] == 'RelDefinesByProperties':\n",
        "                                if relObject['relatingPropertyDefinition']:\n",
        "                                    relatingPropertyDefinition = relObject['relatingPropertyDefinition']\n",
        "                                    if 'hasProperties' in relatingPropertyDefinition:\n",
        "                                        for property in relatingPropertyDefinition['hasProperties']:\n",
        "                                            try:\n",
        "                                                fullObject[property['name']\n",
        "                                                           ] = property['nominalValue']['value']\n",
        "                                            except Exception as e:\n",
        "                                                print(str(e))\n",
        "                                continue\n",
        "                            else:\n",
        "                                print(relObject['type'])\n",
        "                        if attrName in relObject:\n",
        "                            entityAttributes[attr] = relObject[attrName]\n",
        "\n",
        "            attrKey = self.toLowerCamelcase(attr)\n",
        "\n",
        "            # Replace wrappedvalue key names to value\n",
        "            if attrKey == 'wrappedValue':\n",
        "                attrKey = 'value'\n",
        "\n",
        "            jsonValue = self.getAttributeValue(entityAttributes[attr])\n",
        "            if jsonValue is not None:\n",
        "\n",
        "                # Entity names must be stripped of Ifc prefix\n",
        "                if attr == 'type':\n",
        "                    jsonValue = jsonValue[3:]\n",
        "\n",
        "                fullObject[attrKey] = jsonValue\n",
        "        return fullObject\n",
        "\n",
        "    def createReferenceObject(self, entityAttributes, COMPACT=False):\n",
        "        \"\"\"Returns object reference\n",
        "\n",
        "        Parameters:\n",
        "        entityAttributes (dict): Dictionary of IFC object data\n",
        "        COMPACT (boolean): verbose or non verbose IFC.JSON-5a output\n",
        "\n",
        "        Returns:\n",
        "        dict: object containing reference to another object\n",
        "\n",
        "        \"\"\"\n",
        "        ref = {}\n",
        "        if not COMPACT:\n",
        "\n",
        "            # Entity names must be stripped of Ifc prefix\n",
        "            ref['type'] = entityAttributes['type'][3:]\n",
        "        ref['ref'] = entityAttributes['GlobalId']\n",
        "        return ref\n",
        "\n",
        "    def toObj(self, product):\n",
        "        \"\"\"Convert IfcProduct to OBJ mesh\n",
        "\n",
        "        parameters:\n",
        "        product: ifcopenshell ifcProduct instance\n",
        "\n",
        "        Returns:\n",
        "        string: OBJ string\n",
        "        \"\"\"\n",
        "\n",
        "        if product.Representation:\n",
        "            try:\n",
        "                shape = ifcopenshell.geom.create_shape(self.settings, product)\n",
        "\n",
        "                verts = shape.geometry.verts\n",
        "                vertsList = [' '.join(map(str, verts[x:x+3]))\n",
        "                             for x in range(0, len(verts), 3)]\n",
        "                vertString = 'v ' + '\\nv '.join(vertsList) + '\\n'\n",
        "\n",
        "                faces = shape.geometry.faces\n",
        "                facesList = [' '.join(map(str, faces[x:x+3]))\n",
        "                             for x in range(0, len(faces), 3)]\n",
        "                faceString = 'f ' + '\\nf '.join(map(str, facesList)) + '\\n'\n",
        "\n",
        "                return vertString + faceString\n",
        "            except Exception as e:\n",
        "                print(str(e) + ': Unable to generate OBJ data for ' +\n",
        "                      str(product))\n",
        "                return None"
      ],
      "metadata": {
        "id": "xE7zcYFdktyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IFC2JSON4(IFC2JSON):\n",
        "    SCHEMA_VERSION = '0.0.1'\n",
        "\n",
        "    settings = ifcopenshell.geom.settings()\n",
        "    settings.set(settings.USE_WORLD_COORDS, False)\n",
        "\n",
        "    def __init__(self,\n",
        "                 ifcModel,\n",
        "                 COMPACT=False,\n",
        "                 INCLUDE_INVERSE=False,\n",
        "                 EMPTY_PROPERTIES=False,\n",
        "                 NO_OWNERHISTORY=False,\n",
        "                 GEOMETRY=True):\n",
        "        \"\"\"IFC SPF to IFC.JSON-4 writer\n",
        "\n",
        "        parameters:\n",
        "        ifcModel: IFC filePath or ifcopenshell model instance\n",
        "        COMPACT (boolean): if True then pretty print is turned off and references are created without informative \"type\" property\n",
        "        INCLUDE_INVERSE (boolean): if True then inverse relationships will be explicitly added to entities\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        if isinstance(ifcModel, ifcopenshell.file):\n",
        "            self.ifcModel = ifcModel\n",
        "        else:\n",
        "            self.ifcModel = ifcopenshell.open(ifcModel)\n",
        "        # input(dir(self.ifcModel.wrapped_data.header))\n",
        "        # input(self.ifcModel.wrapped_data.header)\n",
        "        # print(dir(self.ifcModel.wrapped_data.header.file_description))\n",
        "        # if self.ifcModel.wrapped_data.header.file_description.this:\n",
        "        #     print(self.ifcModel.wrapped_data.header.file_description[0])\n",
        "        # input()\n",
        "        self.COMPACT = COMPACT\n",
        "        self.INCLUDE_INVERSE = INCLUDE_INVERSE\n",
        "        self.EMPTY_PROPERTIES = EMPTY_PROPERTIES\n",
        "        self.rootObjects = {}\n",
        "\n",
        "        if NO_OWNERHISTORY:\n",
        "            self.remove_ownerhistory()\n",
        "\n",
        "        # adjust GEOMETRY type\n",
        "        if GEOMETRY == 'tessellate':\n",
        "            self.tessellate()\n",
        "        elif GEOMETRY == False:\n",
        "            self.remove_geometry()\n",
        "\n",
        "    def spf2Json(self):\n",
        "        \"\"\"\n",
        "        Create json dictionary structure for all attributes of the objects in the root list\n",
        "        also including inverse attributes (except for IfcGeometricRepresentationContext and IfcOwnerHistory types)\n",
        "        # (?) Check every IFC object to see if it is used multiple times\n",
        "\n",
        "        Returns:\n",
        "        dict: IFC.JSON-4 model structure\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        jsonObjects = []\n",
        "        relationships = []\n",
        "\n",
        "        # Collect all entity types that already have a GlobalId\n",
        "        for entity in self.ifcModel.by_type('IfcRoot'):\n",
        "            if entity.is_a('IfcRelationship'):\n",
        "                relationships.append(entity)\n",
        "            else:\n",
        "                self.rootObjects[entity.id()] = guid.split(\n",
        "                    guid.expand(entity.GlobalId))[1:-1]\n",
        "\n",
        "        # seperately collect all entity types where a GlobalId needs to be added\n",
        "        # for entity in self.ifcModel.by_type('IfcMaterialDefinition'):\n",
        "        #     self.rootObjects[entity.id()] = str(uuid.uuid4())\n",
        "        for entity in self.ifcModel.by_type('IfcShapeRepresentation'):\n",
        "            self.rootObjects[entity.id()] = str(uuid.uuid4())\n",
        "        for entity in self.ifcModel.by_type('IfcOwnerHistory'):\n",
        "            self.rootObjects[entity.id()] = str(uuid.uuid4())\n",
        "        for entity in self.ifcModel.by_type('IfcGeometricRepresentationContext'):\n",
        "            self.rootObjects[entity.id()] = str(uuid.uuid4())\n",
        "\n",
        "        # Seperately add all IfcRelationship entities so they appear at the end of the list\n",
        "        for entity in relationships:\n",
        "            self.rootObjects[entity.id()] = guid.split(\n",
        "                guid.expand(entity.GlobalId))[1:-1]\n",
        "\n",
        "        for key in self.rootObjects:\n",
        "            entity = self.ifcModel.by_id(key)\n",
        "            entityAttributes = entity.__dict__\n",
        "            entityType = entityAttributes['type']\n",
        "            if not entityType == 'IfcOwnerHistory':\n",
        "                if not self.INCLUDE_INVERSE:\n",
        "                    for attr in entity.wrapped_data.get_inverse_attribute_names():\n",
        "                        inverseAttribute = getattr(entity, attr)\n",
        "                        attrValue = self.getAttributeValue(inverseAttribute)\n",
        "                        if not attrValue and attrValue is not False:\n",
        "                            continue\n",
        "                        else:\n",
        "                            entityAttributes[attr] = attrValue\n",
        "\n",
        "            entityAttributes[\"GlobalId\"] = self.rootObjects[entity.id()]\n",
        "            jsonObjects.append(self.createFullObject(entityAttributes))\n",
        "\n",
        "        return {\n",
        "            'type': 'IFC.JSON',\n",
        "            'version': self.SCHEMA_VERSION,\n",
        "            'schemaIdentifier': self.ifcModel.wrapped_data.schema,\n",
        "            'originatingSystem': 'IFC2JSON_python Version ' + self.VERSION,\n",
        "            'preprocessorVersion': 'IfcOpenShell ' + ifcopenshell.version,\n",
        "            'timeStamp': datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
        "            'data': jsonObjects\n",
        "        }\n",
        "\n",
        "    def createFullObject(self, entityAttributes):\n",
        "        \"\"\"Returns complete IFC.JSON-4 object\n",
        "\n",
        "        Parameters:\n",
        "        entityAttributes (dict): Dictionary of IFC object data\n",
        "\n",
        "        Returns:\n",
        "        dict: containing complete IFC.JSON-4 object\n",
        "\n",
        "        \"\"\"\n",
        "        fullObject = {}\n",
        "\n",
        "        for attr in entityAttributes:\n",
        "\n",
        "            # Line numbers are not part of IFC JSON\n",
        "            if attr == 'id':\n",
        "                continue\n",
        "\n",
        "            attrKey = self.toLowerCamelcase(attr)\n",
        "\n",
        "            # Replace wrappedvalue key names to value\n",
        "            if attrKey == 'wrappedValue':\n",
        "                attrKey = 'value'\n",
        "\n",
        "            jsonValue = self.getAttributeValue(entityAttributes[attr])\n",
        "            if jsonValue is not None:\n",
        "                fullObject[attrKey] = jsonValue\n",
        "        return fullObject\n",
        "\n",
        "    def createReferenceObject(self, entityAttributes, COMPACT=False):\n",
        "        \"\"\"Returns object reference\n",
        "\n",
        "        Parameters:\n",
        "        entityAttributes (dict): Dictionary of IFC object data\n",
        "        COMPACT (boolean): verbose or non verbose IFC.JSON-4 output\n",
        "\n",
        "        Returns:\n",
        "        dict: object containing reference to another object\n",
        "\n",
        "        \"\"\"\n",
        "        ref = {}\n",
        "        if not COMPACT:\n",
        "            ref['type'] = entityAttributes['type']\n",
        "        ref['ref'] = entityAttributes['GlobalId']\n",
        "        return ref\n",
        "\n",
        "    def tessellate(self):\n",
        "        \"\"\"Converts all IfcProduct representations to IfcTriangulatedFaceSet\n",
        "        \"\"\"\n",
        "        for product in self.ifcModel.by_type('IfcProduct'):\n",
        "            if product.Representation:\n",
        "                try:\n",
        "                    representation = product.Representation\n",
        "                    old_shapes = representation.Representations\n",
        "                    context = old_shapes[0].ContextOfItems\n",
        "\n",
        "                    tessellated_shape = ifcopenshell.geom.create_shape(\n",
        "                        self.settings, product)\n",
        "\n",
        "                    verts = tessellated_shape.geometry.verts\n",
        "                    vertsList = [verts[i:i+3] for i in range(0, len(verts), 3)]\n",
        "\n",
        "                    faces = tessellated_shape.geometry.faces\n",
        "                    facesList = [faces[i:i+3] for i in range(0, len(faces), 3)]\n",
        "\n",
        "                    pointlist = self.ifcModel.createIfcCartesianPointList3D(\n",
        "                        vertsList)\n",
        "                    shape = self.ifcModel.createIfcTriangulatedFaceSet(pointlist,\n",
        "                        None, None, facesList, None)\n",
        "\n",
        "                    body_representation = self.ifcModel.createIfcShapeRepresentation(\n",
        "                        context, \"Body\", \"Tessellation\", [shape])\n",
        "                    new_representation = self.ifcModel.createIfcProductDefinitionShape(\n",
        "                        None, None, [body_representation])\n",
        "\n",
        "                    representation = tuple(new_representation)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(str(e) + ': Unable to generate OBJ data for ' +\n",
        "                          str(product))\n",
        "\n",
        "    def remove_ownerhistory(self):\n",
        "        for entity in self.ifcModel.by_type('IfcOwnerHistory'):\n",
        "            self.ifcModel.remove(entity)\n",
        "\n",
        "    def remove_geometry(self):\n",
        "        removeTypes = ['IfcLocalPlacement', 'IfcRepresentationMap', 'IfcGeometricRepresentationContext', 'IfcGeometricRepresentationSubContext', 'IfcProductDefinitionShape',\n",
        "                       'IfcMaterialDefinitionRepresentation', 'IfcShapeRepresentation', 'IfcRepresentationItem', 'IfcStyledRepresentation', 'IfcPresentationLayerAssignment', 'IfcTopologyRepresentation']\n",
        "        for ifcType in removeTypes:\n",
        "            # print(ifcType)\n",
        "            # (lambda x: self.ifcModel.remove(x), self.ifcModel.by_type(ifcType))\n",
        "            for entity in self.ifcModel.by_type(ifcType):\n",
        "                self.ifcModel.remove(entity)"
      ],
      "metadata": {
        "id": "Z4wuUp7kUX_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U1-Zj8J0U4nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the input IFC file path\n",
        "ifc_file_path = r\"/content/sample_data/7m900_tue_hello_wall_with_door_roundtrip.ifc\"\n",
        "\n",
        "# Get the directory path and base name of the input file\n",
        "directory = os.path.dirname(ifc_file_path)\n",
        "base_name = os.path.splitext(os.path.basename(ifc_file_path))[0]\n",
        "\n",
        "# Convert IFC to JSON using IFC2JSON4\n",
        "json_file_path_4 = os.path.join(directory, base_name + \"_4.json\")\n",
        "with open(json_file_path_4, 'w') as outfile:\n",
        "    json.dump(IFC2JSON4(ifc_file_path).spf2Json(), outfile, indent=2)\n",
        "\n",
        "# Convert IFC to JSON using IFC2JSON5a\n",
        "json_file_path_5a = os.path.join(directory, base_name + \"_5a.json\")\n",
        "with open(json_file_path_5a, 'w') as outfile:\n",
        "    json.dump(IFC2JSON5a(ifc_file_path).spf2Json(), outfile, indent=2)"
      ],
      "metadata": {
        "id": "sFOda6fXkt2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation Json file ##\n",
        "\n"
      ],
      "metadata": {
        "id": "Z4CWaXDas1Iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from jsonschema import validate, ValidationError\n",
        "\n",
        "# Specify the path to the JSON file to validate\n",
        "jsonFilePath = \"/content/sample_data/7m900_tue_hello_wall_with_door_roundtrip_4.json\"\n",
        "\n",
        "# Load the JSON schema from the file\n",
        "with open(\"/content/sample_data/IFC4x2-entities.json\", \"r\") as schemaFile:\n",
        "    schema = json.load(schemaFile)\n",
        "\n",
        "# Load the JSON instance from the file\n",
        "with open(jsonFilePath, \"r\") as jsonFile:\n",
        "    instance = json.load(jsonFile)\n",
        "\n",
        "try:\n",
        "    validate(instance=instance, schema=schema)\n",
        "    print(\"The JSON instance is valid against the schema.\")\n",
        "except ValidationError as e:\n",
        "    print(\"Validation failed. The JSON instance is not valid against the schema.\")\n",
        "    print(\"Validation error:\", e)\n",
        "\n",
        "    # Access error details\n",
        "    for error in e.errors:\n",
        "        print(\"Error in block:\", \".\".join(str(x) for x in error.path))\n",
        "        print(\"Validation message:\", error.message)\n",
        "\n"
      ],
      "metadata": {
        "id": "pTPYfEIvrIQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "mpYzPpwVrML1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json('/content/sample_data/Duplex_A_20110907_optimized_roundtrip.json')\n"
      ],
      "metadata": {
        "id": "HOoimn1gomNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "GXlxC7E38suc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['data'].iloc[0]"
      ],
      "metadata": {
        "id": "6-tbZSgyBquy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "id": "_F04m4n_6iS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "tlKAeWRV6gH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.values"
      ],
      "metadata": {
        "id": "l33qnbMA8BS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "eC74GcYB8vLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_json(json_data, prefix=''):\n",
        "    flattened_data = {}\n",
        "\n",
        "    for key, value in json_data.items():\n",
        "        new_key = prefix + '.' + key if prefix else key\n",
        "\n",
        "        if isinstance(value, dict):\n",
        "            flattened_data.update(flatten_json(value, prefix=new_key))\n",
        "        elif isinstance(value, list):\n",
        "            for i, item in enumerate(value):\n",
        "                item_key = f\"{new_key}[{i}]\"\n",
        "                if isinstance(item, dict):\n",
        "                    flattened_data.update(flatten_json(item, prefix=item_key))\n",
        "                else:\n",
        "                    flattened_data[item_key] = item\n",
        "        else:\n",
        "            flattened_data[new_key] = value\n",
        "\n",
        "    return flattened_data\n"
      ],
      "metadata": {
        "id": "l92-vJcUtJdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_json1(json_data, columns_to_flatten=[], prefix=''):\n",
        "    flattened_data = {}\n",
        "\n",
        "    for key, value in json_data.items():\n",
        "        new_key = prefix + '.' + key if prefix else key\n",
        "\n",
        "        if key in columns_to_flatten:\n",
        "            if isinstance(value, dict):\n",
        "                flattened_data.update(flatten_json(value, columns_to_flatten, prefix=new_key))\n",
        "            elif isinstance(value, list):\n",
        "                for i, item in enumerate(value):\n",
        "                    item_key = f\"{new_key}[{i}]\"\n",
        "                    if isinstance(item, dict):\n",
        "                        flattened_data.update(flatten_json(item, columns_to_flatten, prefix=item_key))\n",
        "                    else:\n",
        "                        flattened_data[item_key] = item\n",
        "            else:\n",
        "                flattened_data[new_key] = value\n",
        "        else:\n",
        "            flattened_data[new_key] = value\n",
        "\n",
        "    return flattened_data\n"
      ],
      "metadata": {
        "id": "1AIGngH_5OnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_json2(json_data, columns_to_flatten=[], prefix=''):\n",
        "    flattened_data = {}\n",
        "\n",
        "    for key, value in json_data.items():\n",
        "        new_key = prefix + '.' + key if prefix else key\n",
        "\n",
        "        if key in columns_to_flatten:\n",
        "            if isinstance(value, dict):\n",
        "                flattened_data.update(flatten_json(value, columns_to_flatten, prefix=new_key))\n",
        "            elif isinstance(value, list):\n",
        "                for i, item in enumerate(value):\n",
        "                    item_key = f\"{new_key}[{i}]\"\n",
        "                    if isinstance(item, dict):\n",
        "                        flattened_data.update(flatten_json(item, columns_to_flatten, prefix=item_key))\n",
        "                    else:\n",
        "                        flattened_data[item_key] = item\n",
        "            else:\n",
        "                flattened_data[new_key] = value\n",
        "        else:\n",
        "            flattened_data[new_key] = value\n",
        "\n",
        "    return flattened_data\n"
      ],
      "metadata": {
        "id": "_ZdPu8by7Prk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_data = flatten_json(df)"
      ],
      "metadata": {
        "id": "OY_q8ghKt4I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "9s7AtTcRu4hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.io.json import json_normalize\n",
        "data_df = json_normalize(df[\"data\"])"
      ],
      "metadata": {
        "id": "GGptoQ6NuZ8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df\n"
      ],
      "metadata": {
        "id": "vCsiLYU6viSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_flatten = [col for col in data_df.columns if isinstance(data_df[col].iloc[0], list)]\n",
        "columns_to_flatten"
      ],
      "metadata": {
        "id": "gtLUrNGW7R6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the JSON data\n",
        "flattened_data = flatten_json(data_df, columns_to_flatten)\n",
        "\n",
        "# Convert the flattened data to a DataFrame\n",
        "flattened_df = pd.DataFrame.from_dict(flattened_data, orient='index', columns=['Flattened Values'])\n",
        "\n",
        "# Display the flattened DataFrame\n",
        "print(flattened_df)\n"
      ],
      "metadata": {
        "id": "IxStRBHQ7_Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan = data_df.isna().sum()\n",
        "nan"
      ],
      "metadata": {
        "id": "P2T3WsMDwJ1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the percentage of null values for each column\n",
        "null_percentages = (data_df.isnull().sum() / len(data_df)) * 100\n",
        "# Set a threshold for the maximum allowed null percentage\n",
        "threshold = 50  # Adjust the threshold as needed\n",
        "\n",
        "# Filter out columns that exceed the threshold\n",
        "columns_to_remove = null_percentages[null_percentages > threshold].index\n",
        "columns_to_remove\n",
        "# Remove the columns from the DataFrame\n",
        "data_df = data_df.drop(columns=columns_to_remove)\n"
      ],
      "metadata": {
        "id": "MRt81al5wym1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df"
      ],
      "metadata": {
        "id": "-Uj8dnGFxPoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.json_normalize(df['data'], meta=df.columns.drop('data').tolist())\n",
        "data"
      ],
      "metadata": {
        "id": "pgTerfyPpZGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_columns = [col for col in data.columns if isinstance(data[col].iloc[0], list)]\n",
        "list_columns"
      ],
      "metadata": {
        "id": "7qppmqtmKY5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape[0]"
      ],
      "metadata": {
        "id": "WSXF5F9XLOgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_json(json_data, prefix=''):\n",
        "    flattened_data = {}\n",
        "\n",
        "    for key, value in json_data.items():\n",
        "        new_key = prefix + '.' + key if prefix else key\n",
        "\n",
        "        if isinstance(value, dict):\n",
        "            flattened_data.update(flatten_json(value, prefix=new_key))\n",
        "        elif isinstance(value, list):\n",
        "            for i, item in enumerate(value):\n",
        "                item_key = f\"{new_key}[{i}]\"\n",
        "                if isinstance(item, dict):\n",
        "                    flattened_data.update(flatten_json(item, prefix=item_key))\n",
        "                else:\n",
        "                    flattened_data[item_key] = item\n",
        "        else:\n",
        "            flattened_data[new_key] = value\n",
        "\n",
        "    return flattened_data\n",
        "\n",
        "\n",
        "# Read the JSON file\n",
        "with open('/content/sample_data/Duplex_A_20110907_optimized.json', 'r') as file:\n",
        "    json_data = json.load(file)\n",
        "\n",
        "# Flatten the JSON data\n",
        "flattened_data = flatten_json(json_data)\n",
        "\n",
        "# Process or save the flattened data as needed\n",
        "print(flattened_data)\n"
      ],
      "metadata": {
        "id": "5FIyUJT9GiTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_counts = data[list_columns].isna().sum()\n",
        "nan_counts"
      ],
      "metadata": {
        "id": "cw6npN7JKp2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data= data.drop(columns=list_columns)\n",
        "data"
      ],
      "metadata": {
        "id": "mzSgliKSL5Fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "JnEPJiKhJmh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data2[data2.duplicated(keep=False)].shape[0]"
      ],
      "metadata": {
        "id": "Z0w9KrMYIAyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicated_columns = data.columns[data.columns.duplicated()]\n",
        "if len(duplicated_columns) > 0:\n",
        "    print(\"Duplicate columns detected:\", duplicated_columns)\n",
        "else:\n",
        "    print(\"No duplicate columns found.\")\n"
      ],
      "metadata": {
        "id": "SuTqnOeOSuD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in data.items():\n",
        "    print(key, type(value))\n"
      ],
      "metadata": {
        "id": "tu4Nv_8GSFjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "JsDJRDMlXo6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterates over the items of the DataFrame data1 and checks if each value is of type dictionary (dict). If a column's value is a dictionary, it prints a message indicating that the column contains dictionary values.\n",
        "for column, value in data.items():\n",
        "    if isinstance(value, dict):\n",
        "        print(f\"Column '{column}' contains dictionary values.\")"
      ],
      "metadata": {
        "id": "nxgRkiekVybR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# columns which contain only null values in the data1 DataFrame.\n",
        "null_columns = data.columns[data.isnull().all()]\n",
        "null_columns"
      ],
      "metadata": {
        "id": "JyCizbe9QqDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count the number of NaN values in each column of a DataFrame\n",
        "nan_counts = data.isna().sum()\n",
        "print(nan_counts)\n"
      ],
      "metadata": {
        "id": "wyjZssjJW42y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas_profiling import ProfileReport\n"
      ],
      "metadata": {
        "id": "8MssVbSzYi99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile = ProfileReport(data)\n"
      ],
      "metadata": {
        "id": "TLgUlVX3YjE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile.to_widgets()  # Display the report in an interactive widget"
      ],
      "metadata": {
        "id": "01fd98BOYrzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile"
      ],
      "metadata": {
        "id": "FrDvtzBFY0gK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_counts = data.isnull().sum()\n",
        "null_counts"
      ],
      "metadata": {
        "id": "bxJCtdIeQZcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "q_NpH11wXoHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the number of rows in the DataFrame\n",
        "total_rows = len(data)\n",
        "\n",
        "# Define the proportion of rows as the threshold\n",
        "threshold_proportion = 0.8  # Example threshold proportion\n",
        "\n",
        "# Calculate the threshold based on the proportion\n",
        "threshold = threshold_proportion * total_rows\n",
        "threshold"
      ],
      "metadata": {
        "id": "gDt6EzTrRUwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the columns with a high number of null values\n",
        "columns_to_remove = null_counts[null_counts >= threshold].index\n",
        "columns_to_remove"
      ],
      "metadata": {
        "id": "LjPo22DyQkig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = data.drop(columns=columns_to_remove)"
      ],
      "metadata": {
        "id": "uxIrbF0YRRMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1"
      ],
      "metadata": {
        "id": "DkRSYvEEUbXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a column contains lists\n",
        "list_columns = [col for col in data.columns if data[col].apply(lambda x: isinstance(x, list)).any()]\n",
        "list_columns"
      ],
      "metadata": {
        "id": "jxZU9gBRN-m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile = ProfileReport(data1)\n",
        "profile"
      ],
      "metadata": {
        "id": "V_cOGpDJIDS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***BERT***"
      ],
      "metadata": {
        "id": "7qwqzeKpEo6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n"
      ],
      "metadata": {
        "id": "WE-NgrEkYcce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.nn.utils.rnn import pad_sequence\n"
      ],
      "metadata": {
        "id": "mKQxsrTGEq21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "jcyB6FJxYb1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Placeholder for NaN values in the text column\n",
        "nan_placeholder = \" \"\n",
        "def generate_bert_embeddings(text):\n",
        "    # Replace NaN values with the placeholder\n",
        "    text = text if pd.notnull(text) else nan_placeholder\n",
        "\n",
        "    # Tokenize text\n",
        "    tokens = tokenizer.encode(text, add_special_tokens=True)\n",
        "\n",
        "    # Convert tokens to tensors\n",
        "    input_ids = torch.tensor([tokens])\n",
        "\n",
        "    # Generate BERT embeddings\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids)\n",
        "\n",
        "    # Extract the embeddings\n",
        "    embeddings = outputs.last_hidden_state.squeeze(0).mean(0).numpy()\n",
        "    return embeddings\n",
        "\n",
        "# Define the maximum length for tokenization\n",
        "max_length = 512  # Adjust this value as needed\n",
        "\n",
        "# Iterate over the columns and generate BERT embeddings\n",
        "for col in data1.columns:\n",
        "    # Get the text data in the column\n",
        "    text_data = data1[col]\n",
        "\n",
        "    # Generate BERT embeddings for each text entry in the column\n",
        "    embeddings = []\n",
        "    for text in text_data:\n",
        "        # Convert text entry to string\n",
        "        text = str(text)\n",
        "\n",
        "        # Replace NaN values with the placeholder\n",
        "        text = text if pd.notnull(text) else nan_placeholder\n",
        "\n",
        "        # Tokenize text\n",
        "        tokens = tokenizer.encode(text, add_special_tokens=True)\n",
        "\n",
        "        # Truncate the tokens to the maximum length\n",
        "        tokens = tokens[:max_length]\n",
        "\n",
        "        # Convert tokens to tensors\n",
        "        input_ids = torch.tensor([tokens])\n",
        "\n",
        "        # Generate BERT embeddings\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids)\n",
        "\n",
        "        # Extract the embeddings\n",
        "        embedding = outputs.last_hidden_state.squeeze(0).mean(0).numpy()\n",
        "\n",
        "        # Append the embedding to the list\n",
        "        embeddings.append(embedding.tolist())\n",
        "\n",
        "    # Store the embeddings in a new column\n",
        "    data1[col + '_embeddings'] = embeddings\n",
        "\n",
        "# Display the updated DataFrame with BERT embeddings\n",
        "print(data_df)\n"
      ],
      "metadata": {
        "id": "Gc3fIMFkYia8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo"
      ],
      "metadata": {
        "id": "CNRJ8fzcTGuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo"
      ],
      "metadata": {
        "id": "qvC7pwaGThI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo\n",
        "import urllib.parse\n",
        "\n",
        "# Replace the connection details with your own\n",
        "username = \"admin\"\n",
        "password = \"wF3bJ%Fg\"\n",
        "host = \"18.170.83.79\"\n",
        "port = \"8081\"\n",
        "\n",
        "# Escape special characters in the username and password\n",
        "escaped_username = urllib.parse.quote_plus(username)\n",
        "escaped_password = urllib.parse.quote_plus(password)\n",
        "\n",
        "# Construct the connection string\n",
        "connection_string = f\"mongodb://{escaped_username}:{escaped_password}@{host}:{port}\"\n",
        "\n",
        "# Connect to MongoDB using the connection string\n",
        "client = pymongo.MongoClient(connection_string)"
      ],
      "metadata": {
        "id": "cuOXrgJoTkaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = client[\"admin\"]\n",
        "collection = db[\"\"]"
      ],
      "metadata": {
        "id": "EyXdUIf9ZUAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "# import torch\n",
        "# from transformers import BertTokenizer, BertModel\n",
        "# from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# # Load JSON data\n",
        "# with open('/content/sample_data/7m900_tue_hello_wall_with_door.json', 'r') as f:\n",
        "#     json_data = json.load(f)\n",
        "\n",
        "# # Load BERT model and tokenizer\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# # Initialize a list to store embeddings\n",
        "# embeddings = []\n",
        "\n",
        "# # Iterate over the JSON data\n",
        "# for item in json_data:\n",
        "#     text = item['text']\n",
        "\n",
        "#     # Tokenize text\n",
        "#     tokens = tokenizer.encode(text, add_special_tokens=True)\n",
        "\n",
        "#     # Pad or truncate the sequences to the same length\n",
        "#     max_length = 10  # Define the desired maximum length\n",
        "#     padded_tokens = tokens[:max_length] + [0] * (max_length - len(tokens[:max_length]))\n",
        "\n",
        "#     # Convert tokens to tensors\n",
        "#     input_ids = torch.tensor(padded_tokens)\n",
        "\n",
        "#     # Generate BERT embeddings\n",
        "#     with torch.no_grad():\n",
        "#         outputs = model(input_ids.unsqueeze(0))  # Add an extra dimension for batch processing\n",
        "\n",
        "#     # Extract the embeddings\n",
        "#     embedding = outputs.last_hidden_state.squeeze(0).mean(0).numpy()\n",
        "\n",
        "#     # Store the embedding along with other relevant data\n",
        "#     item['embedding'] = embedding.tolist()\n",
        "\n",
        "#     embeddings.append(item)\n",
        "\n",
        "# # Save the embeddings with updated JSON data\n",
        "# with open('embeddings.json', 'w') as f:\n",
        "#     json.dump(embeddings, f)"
      ],
      "metadata": {
        "id": "UOmSiFSWArrN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}